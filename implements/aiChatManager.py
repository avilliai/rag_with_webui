from abc import ABC, abstractmethod
from typing import List, Dict, Optional, Generator
import json


class BaseChatManager(ABC):
    """AIå¯¹è¯ç®¡ç†å™¨æŠ½è±¡åŸºç±»"""

    def __init__(self, model_name: str):
        self.model_name = model_name

    @abstractmethod
    def rewrite_query(self, query: str) -> str:
        """é‡å†™æŸ¥è¯¢ä»¥ä¼˜åŒ–æ£€ç´¢"""
        pass

    @abstractmethod
    def generate_answer(self, prompt: str, chat_history: Optional[List[Dict]] = None) -> str:
        """ç”Ÿæˆç­”æ¡ˆï¼ˆéæµå¼ï¼‰"""
        pass

    @abstractmethod
    def generate_answer_stream(
            self,
            prompt: str,
            chat_history: Optional[List[Dict]] = None
    ) -> Generator[str, None, None]:
        """ç”Ÿæˆç­”æ¡ˆï¼ˆæµå¼ï¼‰"""
        pass

    def build_rag_prompt(self, query: str, context_items: List[Dict]) -> str:
        """æ„å»ºRAGæç¤ºè¯"""
        context_parts = []
        print("\nğŸ“š æ„å»ºæœ€ç»ˆä¸Šä¸‹æ–‡:")
        for item in context_items:
            meta = item['meta']
            source_info = f"[æ¥æº: {meta.get('source', 'æœªçŸ¥')} | ç« èŠ‚: {meta.get('section_path', 'N/A')}]"
            hit_marker = "ğŸ¯" if item.get('is_hit') else "ğŸ“„"
            print(f"   {hit_marker} {source_info}")
            context_parts.append(f"{source_info}\n{item['doc']}")

        context = "\n\n---\n\n".join(context_parts)
        print(f"\nğŸ” æœ€ç»ˆä¸Šä¸‹æ–‡åŒ…å« {len(context_parts)} ä¸ªæ–‡æ¡£å—, æ€»é•¿åº¦ {len(context)} å­—ç¬¦")

        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ”¿æ²»å­¦çŸ¥è¯†è§£ç­”æ¨¡å‹ã€‚è¯·ä¸¥æ ¼åŸºäºä»¥ä¸‹æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹ï¼Œä»¥ç³»ç»Ÿã€å­¦æœ¯åŒ–çš„æ–¹å¼å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
- ç»¼åˆæ‰€æœ‰æä¾›çš„ä¿¡æ¯ï¼Œç»™å‡ºå…¨é¢è€Œæœ‰æ¡ç†çš„ç­”æ¡ˆã€‚
- å¦‚æœæ–‡æ¡£å†…å®¹ä¸è¶³ä»¥å›ç­”ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºã€‚
- ä»¥Markdownæ ¼å¼è¿›è¡Œå›å¤ã€‚

--- [æ£€ç´¢åˆ°çš„æ–‡æ¡£] ---
{context}
--- [æ£€ç´¢åˆ°çš„æ–‡æ¡£ç»“æŸ] ---

é—®é¢˜: {query}

è¯·æä¾›è¯¦ç»†ä¸”å‡†ç¡®çš„ç­”æ¡ˆ:"""


class GeminiChatManager(BaseChatManager):
    """Gemini AIå¯¹è¯ç®¡ç†å™¨"""

    def __init__(self, api_key: str, model_name: str = "gemini-2.5-flash"):
        super().__init__(model_name)
        import google.generativeai as genai
        genai.configure(api_key=api_key)
        self.genai = genai
        self.chat_model = genai.GenerativeModel(model_name)
        print(f"âœ… Gemini æ¨¡å‹åˆå§‹åŒ–å®Œæˆ: {model_name}")

    def rewrite_query(self, query: str) -> str:
        """ä½¿ç”¨Geminié‡å†™æŸ¥è¯¢"""
        print(f"\nğŸ”„ æ­£åœ¨é‡å†™æŸ¥è¯¢ (Gemini)...")
        prompt = f"""ä½ æ˜¯ä¸€åæ£€ç´¢ä¼˜åŒ–ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹ç”¨æˆ·é—®é¢˜æ”¹å†™ä¸ºä¸€ä¸ªä¿¡æ¯æ›´ä¸°å¯Œçš„é™ˆè¿°å¥ï¼Œç”¨äºå‘é‡æ•°æ®åº“çš„è¯­ä¹‰æ£€ç´¢ã€‚è¯·ä¸“æ³¨äºæ ¸å¿ƒæ„å›¾ï¼Œè¡¥å……å¯èƒ½çš„ä¸Šä¸‹æ–‡ï¼Œä½¿å…¶æ›´åƒä¸€ä¸ª"ç­”æ¡ˆ"çš„ç‰‡æ®µã€‚
ç›´æ¥è¿”å›æ”¹å†™åçš„æ–‡æœ¬ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–å‰ç¼€ã€‚

åŸå§‹é—®é¢˜: "{query}"

æ”¹å†™åçš„æ£€ç´¢æŸ¥è¯¢:
"""
        try:
            response = self.chat_model.generate_content(prompt)
            rewritten_query = response.text.strip().replace("*", "")
            print(f"   - åŸå§‹æŸ¥è¯¢: {query}")
            print(f"   - é‡å†™å: {rewritten_query}")
            return rewritten_query
        except Exception as e:
            print(f"âš ï¸ æŸ¥è¯¢é‡å†™å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨åŸå§‹æŸ¥è¯¢ã€‚")
            return query

    def generate_answer(self, prompt: str, chat_history: Optional[List[Dict]] = None) -> str:
        """ä½¿ç”¨Geminiç”Ÿæˆç­”æ¡ˆï¼ˆéæµå¼ï¼‰"""
        try:
            print("\nğŸ’¡ æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ (Gemini)...")

            if chat_history:
                # ä½¿ç”¨èŠå¤©ä¼šè¯
                chat = self.chat_model.start_chat(history=chat_history)
                response = chat.send_message(prompt)
            else:
                response = self.chat_model.generate_content(prompt)

            return response.text
        except Exception as e:
            return f"âŒ ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™: {e}"

    def generate_answer_stream(
            self,
            prompt: str,
            chat_history: Optional[List[Dict]] = None
    ) -> Generator[str, None, None]:
        """ä½¿ç”¨Geminiç”Ÿæˆç­”æ¡ˆï¼ˆæµå¼ï¼‰"""
        try:
            if chat_history:
                chat = self.chat_model.start_chat(history=chat_history)
                response = chat.send_message(prompt, stream=True)
            else:
                response = self.chat_model.generate_content(prompt, stream=True)

            for chunk in response:
                if chunk.text:
                    yield json.dumps({
                        'type': 'content',
                        'content': chunk.text
                    }, ensure_ascii=False) + '\n'

            yield json.dumps({
                'type': 'done',
                'content': ''
            }, ensure_ascii=False) + '\n'
        except Exception as e:
            yield json.dumps({
                'type': 'error',
                'content': f'ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™: {str(e)}'
            }, ensure_ascii=False) + '\n'


class OpenAIChatManager(BaseChatManager):
    """OpenAIå¯¹è¯ç®¡ç†å™¨"""

    def __init__(
            self,
            api_key: str,
            model_name: str = "gpt-4-turbo-preview",
            base_url: Optional[str] = None
    ):
        super().__init__(model_name)
        from openai import OpenAI

        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url  # æ”¯æŒè‡ªå®šä¹‰endpointï¼ˆå¦‚OpenAIå…¼å®¹æ¥å£ï¼‰
        )
        print(f"âœ… OpenAI æ¨¡å‹åˆå§‹åŒ–å®Œæˆ: {model_name}")

    def rewrite_query(self, query: str) -> str:
        """ä½¿ç”¨OpenAIé‡å†™æŸ¥è¯¢"""
        print(f"\nğŸ”„ æ­£åœ¨é‡å†™æŸ¥è¯¢ (OpenAI)...")
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€åæ£€ç´¢ä¼˜åŒ–ä¸“å®¶ã€‚å°†ç”¨æˆ·é—®é¢˜æ”¹å†™ä¸ºä¿¡æ¯æŒ‡å‘æ›´æ˜ç¡®çš„ç®€å•é™ˆè¿°å¥ï¼Œç”¨äºå‘é‡æ•°æ®åº“çš„è¯­ä¹‰æ£€ç´¢ã€‚è¯·ä¸“æ³¨äºæ ¸å¿ƒæ„å›¾ã€‚"
                    },
                    {
                        "role": "user",
                        "content": f'åŸå§‹é—®é¢˜: "{query}"\n\næ”¹å†™åçš„æ£€ç´¢æŸ¥è¯¢:'
                    }
                ],
                temperature=0.3,
                max_tokens=200
            )

            rewritten_query = response.choices[0].message.content.strip()
            print(f"   - åŸå§‹æŸ¥è¯¢: {query}")
            print(f"   - é‡å†™å: {rewritten_query}")
            return rewritten_query
        except Exception as e:
            print(f"âš ï¸ æŸ¥è¯¢é‡å†™å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨åŸå§‹æŸ¥è¯¢ã€‚")
            return query

    def generate_answer(self, prompt: str, chat_history: Optional[List[Dict]] = None) -> str:
        """ä½¿ç”¨OpenAIç”Ÿæˆç­”æ¡ˆï¼ˆéæµå¼ï¼‰"""
        try:
            print("\nğŸ’¡ æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ (OpenAI)...")

            messages = []

            # æ·»åŠ å†å²è®°å½•
            if chat_history:
                for msg in chat_history:
                    messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })

            # æ·»åŠ å½“å‰prompt
            messages.append({
                "role": "user",
                "content": prompt
            })

            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=0.7,
                max_tokens=2000
            )

            return response.choices[0].message.content
        except Exception as e:
            return f"âŒ ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™: {e}"

    def generate_answer_stream(
            self,
            prompt: str,
            chat_history: Optional[List[Dict]] = None
    ) -> Generator[str, None, None]:
        """ä½¿ç”¨OpenAIç”Ÿæˆç­”æ¡ˆï¼ˆæµå¼ï¼‰"""
        try:
            messages = []

            # æ·»åŠ å†å²è®°å½•
            if chat_history:
                for msg in chat_history:
                    messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })

            # æ·»åŠ å½“å‰prompt
            messages.append({
                "role": "user",
                "content": prompt
            })

            stream = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=0.7,
                max_tokens=2000,
                stream=True
            )

            for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield json.dumps({
                        'type': 'content',
                        'content': chunk.choices[0].delta.content
                    }, ensure_ascii=False) + '\n'

            yield json.dumps({
                'type': 'done',
                'content': ''
            }, ensure_ascii=False) + '\n'
        except Exception as e:
            yield json.dumps({
                'type': 'error',
                'content': f'ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™: {str(e)}'
            }, ensure_ascii=False) + '\n'


class SessionManager:
    """ä¼šè¯ç®¡ç†å™¨ - ç®¡ç†ä¸åŒAIæä¾›å•†çš„å¯¹è¯å†å²"""

    def __init__(self):
        # æ ¼å¼: {session_id: {'provider': 'gemini'/'openai', 'history': [...]}}
        self.sessions: Dict[str, Dict] = {}

    def create_session(self, session_id: str, provider: str = 'gemini') -> None:
        """åˆ›å»ºæ–°ä¼šè¯"""
        self.sessions[session_id] = {
            'provider': provider,
            'history': []
        }

    def get_session(self, session_id: str) -> Optional[Dict]:
        """è·å–ä¼šè¯"""
        return self.sessions.get(session_id)

    def add_message(self, session_id: str, role: str, content: str) -> None:
        """æ·»åŠ æ¶ˆæ¯åˆ°ä¼šè¯å†å²"""
        if session_id not in self.sessions:
            return

        provider = self.sessions[session_id]['provider']

        if provider == 'gemini':
            #print(role)
            # Geminiæ ¼å¼
            self.sessions[session_id]['history'].append({
                'role': role,
                'parts': [{'text': content}]
            })
        else:  # OpenAIæ ¼å¼
            self.sessions[session_id]['history'].append({
                'role': role,
                'content': content
            })

    def get_history(self, session_id: str) -> List[Dict]:
        """è·å–ä¼šè¯å†å²"""
        session = self.sessions.get(session_id)
        return session['history'] if session else []

    def clear_session(self, session_id: str) -> None:
        """æ¸…ç©ºä¼šè¯å†å²"""
        if session_id in self.sessions:
            self.sessions[session_id]['history'] = []

    def delete_session(self, session_id: str) -> None:
        """åˆ é™¤ä¼šè¯"""
        if session_id in self.sessions:
            del self.sessions[session_id]

    def get_provider(self, session_id: str) -> Optional[str]:
        """è·å–ä¼šè¯ä½¿ç”¨çš„AIæä¾›å•†"""
        session = self.sessions.get(session_id)
        return session['provider'] if session else None